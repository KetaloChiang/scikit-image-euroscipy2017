{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image filtering, using pixel neighbors\n",
    "\n",
    "So far, we have used only pixel values to process images. However, we can do more advanced image processing using spatial information about pixels and their neighbors. Indeed, in natural images neighboring pixels tend to have similar intensities, to belong to the same object, etc.\n",
    "\n",
    "Here we will see:\n",
    "\n",
    "- how to filter images, i.e. how to modify pixel values according to neighboring values (e.g. for denoising, edge detection, or image cleaning).\n",
    "\n",
    "- how to segment an object, i.e. how to attribute labels to pixels, corresponding to different objects.\n",
    "\n",
    "![plot label](plot_label.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code is only for visualization, you don't have to look at it.\n",
    "\n",
    "from skimage import img_as_float\n",
    "\n",
    "def imshow_all(*images, **kwargs):\n",
    "    \"\"\" Plot a series of images side-by-side.\n",
    "\n",
    "    Convert all images to float so that images have a common intensity\n",
    "    range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    limits : str\n",
    "        Control the intensity limits. By default, 'image' is used set the\n",
    "        min/max intensities to the min/max of all images. Setting `limits` to\n",
    "        'dtype' can also be used if you want to preserve the image exposure.\n",
    "    titles : list of str\n",
    "        Titles for subplots. If the length of titles is less than the number\n",
    "        of images, empty strings are appended.\n",
    "    kwargs : dict \n",
    "        Additional keyword-arguments passed to `imshow`.\n",
    "    \"\"\"\n",
    "    images = [img_as_float(img) for img in images]\n",
    "\n",
    "    titles = kwargs.pop('titles', [])\n",
    "    if len(titles) != len(images):\n",
    "        titles = list(titles) + [''] * (len(images) - len(titles))\n",
    "\n",
    "    limits = kwargs.pop('limits', 'image')\n",
    "    if limits == 'image':\n",
    "        kwargs.setdefault('vmin', min(img.min() for img in images))\n",
    "        kwargs.setdefault('vmax', max(img.max() for img in images))\n",
    "    elif limits == 'dtype':\n",
    "        vmin, vmax = dtype_limits(images[0])\n",
    "        kwargs.setdefault('vmin', vmin)\n",
    "        kwargs.setdefault('vmax', vmax)\n",
    "\n",
    "    nrows, ncols = kwargs.get('shape', (1, len(images)))\n",
    "\n",
    "    size = nrows * kwargs.pop('size', 5)\n",
    "    width = size * len(images)\n",
    "    if nrows > 1:\n",
    "        width /= nrows * 1.33\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(width, size))\n",
    "    for ax, img, label in zip(axes.ravel(), images, titles):\n",
    "        ax.imshow(img, **kwargs)\n",
    "        ax.set_title(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image filtering\n",
    "\n",
    "Linear filters are a convolution between an image and a local kernel, which mixes together pixel values in a neighbourhood of the central pixel. The local kernel can take different values, and also have different supports (square, diamond, disk...).\n",
    "\n",
    "![Local kernels](kernels.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, filters\n",
    "coins = data.coins()\n",
    "coins_zoom = coins[10:80, 300:370]\n",
    "plt.imshow(coins_zoom, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to use two different denoising filters:\n",
    "\n",
    "- the **gaussian kernel** (a square kernel with Gaussian weights) smoothes out noise, but also image features (such as edges)\n",
    "\n",
    "- the **median filter** replaces a pixel by the median value in a neighbourhood. It also decreases noise, but is better at keeping sharp edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_coins = filters.gaussian(coins_zoom, 2)\n",
    "plt.imshow(gaussian_coins, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_coins = filters.rank.median(coins_zoom, np.ones((3, 3)))\n",
    "plt.imshow(median_coins, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Visualize and print the weights of the Gaussian kernel (for sigma=1), using an image with a single non-zero pixel (a \"delta-function\" in mathematical terms).\n",
    "</div>\n",
    "\n",
    "![delta gaussian](delta_gaussian.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical morphology\n",
    "\n",
    "Morphology is the study of shapes. In image processing, some simple operations can get you a long way. The first things to learn are *erosion* and *dilation*. In erosion, we look at a pixel’s local neighborhood and replace the value of that pixel with the minimum value of that neighborhood. In dilation, we instead choose the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'cubehelix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, 1, 1, 0, 0],\n",
    "                  [0, 0, 1, 1, 1, 0, 0],\n",
    "                  [0, 0, 1, 1, 1, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0]], dtype=np.uint8)\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for scikit-image's morphology module is\n",
    "[here](http://scikit-image.org/docs/0.10.x/api/skimage.morphology.html).\n",
    "\n",
    "Importantly, we must use a *structuring element*, which defines the local\n",
    "neighborhood of each pixel. To get every neighbor (up, down, left, right, and\n",
    "diagonals), use `morphology.square`; to avoid diagonals, use\n",
    "`morphology.diamond`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "sq = morphology.square(width=3)\n",
    "dia = morphology.diamond(radius=1)\n",
    "print(\"square:\\n\", sq)\n",
    "print(\"diamond:\\n\", dia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central value of the structuring element represents the pixel being considered, and the surrounding values are the neighbors: a 1 value means that pixel counts as a neighbor, while a 0 value does not. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eroded = morphology.erosion(image, dia)\n",
    "imshow_all(image, eroded, shape=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded_too_much = morphology.erosion(image, morphology.square(5))\n",
    "imshow_all(image, eroded_too_much, shape=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dil_dia = morphology.dilation(eroded, dia)\n",
    "imshow_all(eroded, dil_dia, shape=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dil_sq = morphology.dilation(eroded, sq)\n",
    "imshow_all(eroded, dil_sq, shape=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: clean a noisy image.\n",
    "    \n",
    "Below we create a binary image with large blobs, but also some random noise (that could have generated from thresholding a noisy image, for example). Let's try to clean it without altering too much the shape of the blobs, using mathematical morphology.\n",
    "    \n",
    "To remove small 0-valued (black) objects, you can use a combination of dilation followed by erosion, called closing (``skimage.morphology.binary_closing``). To remove small 1-valued (white) objects, you can use the reverse combination: erosion followed by dilation, called opening.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = data.binary_blobs() - 0.5\n",
    "im += 0.4 * np.random.randn(*im.shape)\n",
    "noisy_im = im > 0\n",
    "plt.imshow(noisy_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation\n",
    "\n",
    "Image segmentation consists in attributing labels to pixels, corresponding to objects of interest (for example, object and background). We have already seen several segmentation strategies:\n",
    "\n",
    "- simple thresholding\n",
    "- thresholding with pre-processing (such as image denoising, e.g. with a median filter) or post-pocessing(e.g. cleaning a binary image with mathematical morphology).\n",
    "\n",
    "More advanced algorithms are possible and require less hand-tuning of pre- or post-processing. However, they all require user-supplied information. Even machine-learning (e.g. deep learning) algorithms, which detect objects automatically, have used huge training sets for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'viridis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marker-based segmentation\n",
    "\n",
    "Let's start with the **marker-based** approach. Remember this coins image with an uneven illumination? Simple thresholding did not work well, but fortunately we can use the tails of the histogram: the brightest pixels do correspond to coins, and the darkest to the background. Therefore, we will be able to use these pixel as **markers**, which will **propagate their label** to neighboring pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = data.coins()\n",
    "plt.imshow(coins, cmap='gray')\n",
    "print(filters.threshold_otsu(coins))\n",
    "cs = plt.contour(coins, [30, 100, 150], cmap='plasma')\n",
    "plt.colorbar(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = filters.sobel(coins)\n",
    "markers = np.zeros_like(coins)\n",
    "background, foreground = 1, 2\n",
    "markers[coins < 30.0] = background\n",
    "markers[coins > 150.0] = foreground\n",
    "\n",
    "from skimage import segmentation\n",
    "ws = segmentation.watershed(edges, markers)\n",
    "\n",
    "# Figure\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(markers)\n",
    "plt.title('Markers')\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(edges)\n",
    "plt.title('Edges')\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(ws)\n",
    "plt.title('Watershed segmentation')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Going further**: for the marker-based strategy, also consider using the [random walker algorithm](http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_random_walker_segmentation.html), which is more robust to noise (but is slower and requires more memory than the watershed).\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging-based segmentation\n",
    "\n",
    "Instead of choosing known markers (e.g. using the histogram), it is also possible to make an over-segmentation using seeds, which can be placed at random or on a regular grid. Each seed will propagate to neighboring pixels with similar gray levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util, color\n",
    "grid = util.regular_grid(coins.shape, n_points=100)\n",
    "\n",
    "seeds = np.zeros(coins.shape, dtype=int)\n",
    "seeds[grid] = np.arange(seeds[grid].size).reshape(seeds[grid].shape) + 1\n",
    "\n",
    "ws_seeds = segmentation.watershed(edges, seeds, compactness=0.01)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax0.imshow(coins, cmap='gray')\n",
    "ax0.contour(seeds > 0, colors='y', linewidths=4)\n",
    "ax0.set_title('Image with seeds')\n",
    "\n",
    "ax1.imshow(color.label2rgb(ws_seeds, coins))\n",
    "ax1.set_title('Compact watershed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A post-processing step is needed to merge together regions belonging to the same object. This is not covered here, but you can read [this example](http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_rag_mean_color.html) or [this other example](http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_boundary_merge.html)  to know more about region merging.\n",
    "\n",
    "**See also**: more [segmentation examples](http://scikit-image.org/docs/stable/auto_examples/#segmentation-of-objects) in scikit-image gallery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling objects and measuring their properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "labels = measure.label(ws)\n",
    "plt.imshow(labels)\n",
    "print(\"number of coins:\", labels.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels == 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = measure.regionprops(labels, coins)\n",
    "print(properties)\n",
    "print(dir(properties[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [prop.area for prop in properties]\n",
    "print(\"areas:\", areas)\n",
    "mean_intensities = [prop.mean_intensity for prop in properties]\n",
    "print(\"mean intensities:\", mean_intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mid-level features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen\n",
    "\n",
    "- how to modify pixel values using a very local neighbourhood \n",
    "\n",
    "- how to segment a whole image into labeled regions.\n",
    "\n",
    "For some applications it is also interesting to detect mid-level features, such as edges, corner, high gradients, etc. Such features can be used for image classification of for image registration.\n",
    "\n",
    "Here we only briefly show two examples: edge detection with Canny filter, and corner detection with Harris\n",
    "\n",
    "### Edge detection with Canny filter\n",
    "\n",
    "The Canny filter performs a hysteresis thresholding on the norm of the gradient (Sobel filter). Therefore, it tends to produce connected edges, with less noise than just thresholding the output of the Sobel filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "canny = feature.canny(coins)\n",
    "plt.imshow(canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel = filters.sobel(coins)\n",
    "plt.imshow(sobel)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sobel > 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.text()\n",
    "coords= feature.corner_peaks(feature.corner_harris(text), \n",
    "                             min_distance=3)\n",
    "plt.imshow(text, cmap='gray')\n",
    "plt.plot(coords[:, 1], coords[:, 0], '+r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://scikit-image.org/docs/dev/auto_examples/#detection-of-features-and-objects for more examples of feature detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
